<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>FoSSIL: Continual Semantic Segmentation & Baselines</title>

  <!-- MathJax -->
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async
          src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>

  <!-- Styles -->
  <style>
    body {
      font-family: Arial, sans-serif;
      max-width: 1000px;
      margin: auto;
      padding: 20px;
      line-height: 1.6;
      background-color: #fafafa;
      color: #2c3e50;
    }

    h1, h2, h3 {
      color: #2c3e50;
      margin-bottom: 10px;
    }

    h1 {
      text-align: center;
      margin-bottom: 20px;
    }

    h2, h3 {
      margin-top: 30px;
    }

    p {
      text-align: justify;
    }

    a {
      color: #2980b9;
      text-decoration: none;
    }

    a:hover {
      text-decoration: underline;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      margin-bottom: 20px;
      display: block;
      overflow-x: auto;
    }

    th, td {
      border: 1px solid #ddd;
      padding: 8px;
      text-align: center;
      white-space: nowrap;
    }

    th {
      background-color: #f2f2f2;
      position: sticky;
      top: 0;
      z-index: 1;
    }

    .center {
      text-align: center;
    }

    .note {
      font-style: italic;
      color: #555;
      margin-bottom: 20px;
    }

    ul {
      margin-bottom: 20px;
      padding-left: 20px;
    }

    li {
      margin-bottom: 8px;
    }

    img {
      display: block;
      margin: auto;
      max-width: 100%;
      height: auto;
    }

    hr {
      margin: 30px 0;
      border: 1px solid #ddd;
    }

    /* Responsive math */
    .math {
      display: block;
      text-align: center;
      margin: 10px 0;
    }
  </style>
</head>
<body>

  <h1>FoSSIL: A Unified Framework for Continual Semantic Segmentation in 2D and 3D Domains</h1>

  <p class="center">
    <a href="https://github.com/anony34/FoSSIL/" target="_blank">[GitHub Code]</a>
  </p>

  <hr>

  <h2>Abstract</h2>
  <p>Continual semantic segmentation remains an underexplored area in both 2D and 3D domains. The problem becomes particularly challenging when classes and domains evolve over time, with incremental classes having only a few labeled samples. In this setting, the model must simultaneously address catastrophic forgetting of old classes, overfitting due to the limited labeled data of new classes, and domain shifts arising from changes in data distribution. Existing methods fail to simultaneously address these real-world constraints. We introduce the FoSSIL framework, which integrates guided noise injection and prototype-guided pseudo-label refinement (PLR) to enhance continual learning across class-incremental (CIL), domain-incremental (DIL), and few-shot scenarios. Guided noise injection perturbs parameters with overfitted or saturated gradients more strongly, while perturbing parameters with highly changing or large gradients less, preserving critical weights, allowing less critical parameters to explore alternative solutions in the parameter space, mitigating forgetting, reducing overfitting, and improving robustness to domain shifts. For incremental classes with unlabeled data, PLR enables semi-supervised learning by refining pseudo-labels and filtering out incorrect high-confidence predictions, ensuring reliable supervision for incremental classes. Together, these components work synergistically to enhance stability, generalization, and continual learning across all learning regimes.</p>

  <h2>FoSSIL Framework</h2>

  <h3>Problem Definition</h3>
  <p>We formalize the multi-constrained continual learning problem for semantic segmentation as a sequence of sessions 
  \( \mathcal{S} = \{\mathcal{S}_0, \mathcal{S}_1, \dots, \mathcal{S}_T\} \) where each session \( \mathcal{S}_t \) has a semantic class space \( \mathcal{C}_t \) and domain distribution \( \mathcal{D}_t \). Each session has a dataset 
  \( \mathbb{D}_t = \{(x_i, y_i)\}_{i=1}^{N_t} \) with input images \( x_i \in \mathcal{X} \) and pixel-wise labels \( y_i \in \mathcal{Y}_t \subseteq \mathcal{C}_t \).</p>

  <h3>Classes, Domains, and Data Across Sessions</h3>
  <ul>
    <li><b>Same Classes, Different Domains:</b> \( \mathcal{C}_t = \mathcal{C}_{t'} \), \( \mathcal{D}_t \neq \mathcal{D}_{t'} \)</li>
    <li><b>Different Classes, Same Domain:</b> \( \mathcal{C}_t \neq \mathcal{C}_{t'} \), \( \mathcal{D}_t = \mathcal{D}_{t'} \)</li>
    <li><b>Different Classes, Different Domain:</b> \( \mathcal{C}_t \neq \mathcal{C}_{t'} \), \( \mathcal{D}_t \neq \mathcal{D}_{t'} \)</li>
  </ul>

  <h3>Few-shot Learning</h3>
  <p>Incremental sessions (\( t \neq 0 \)) have few-shot labeled data \( N_t \ll N_0 \), with \( N_t = K \cdot |\mathcal{C}_t| \), where \( K \in \{5,10,20,30\} \). Each session may also access unlabeled data \( \mathcal{U}_t = \{x_j^{(u)}\}_{j=1}^{M_t} \), where \( M_t \gg N_t \).</p>

  <h3>Exemplar-Free Prototype Replay</h3>
  <p>For each class \( c \in \mathcal{C}_t \), a compact prototype is extracted from the feature space using a model feature extractor \( \phi \). For each sample \( (x_i, y_i) \), the embedding is \( E_i = \phi(x_i) \). The class prototype is computed as:</p>
  <p class="math">\( p_c^{(i)} = \frac{1}{|\mathcal{F}_c^{(i)}|} \sum_{\mathbf{f} \in \mathcal{F}_c^{(i)}} \mathbf{f} \)</p>
  <p class="math">\( P_c = \frac{1}{NS_c} \sum_{j \in NS_c} \frac{p_c^{(j)}}{\|p_c^{(j)}\|_2} \)</p>
  <p>The prototype replay loss is:</p>
  <p class="math">\( \mathcal{L}_{\text{proto}} = \sum_{P_c \in \mathcal{P}_t} \mathcal{L}_{\text{CE}}(F(P_c), c) \)</p>

  <h3>Guided Noise Injection</h3>
  <p>Weights are perturbed according to gradient-based guidance:</p>
  <p class="math">\( G_{ij}^{-1} = \frac{1}{G_{ij} + \epsilon} \)</p>
  <p class="math">\( \tilde{G}_{ij}^{-1} = \frac{1 + G_{ij}^{-1} - \min(G^{-1})}{1 + \max(G^{-1}) - \min(G^{-1})} \)</p>
  <p class="math">\( \tilde{\mathbb{W}} = \mathbb{W} + \tilde{G}^{-1} \odot \mathcal{N}(0, I) \)</p>

  <h3>Prototype-Guided Pseudo-Label Refinement (PLR)</h3>
  <p>PLR uses class prototypes to refine pseudo-labels for unlabeled data \( x_j^{(u)} \), ensuring reliable supervision for incremental classes. Student and teacher networks generate pseudo-labels:</p>
  <p class="math">\( \hat{y}_s, \mathcal{F}_s = M_s(x_j^{(u)}), \quad \hat{y}_t, \mathcal{F}_t = M_t(x_j^{(u)}) \)</p>
  <p>Pseudo-labels are retained only if confidence and feature similarity with prototypes meet thresholds:</p>
  <p class="math">\( \text{valid}(p,q) = (\text{conf}(p,q) > \tau_{\text{conf}}) \land (\text{sim}(p,q) > \tau_{\text{sim}}) \)</p>
  <p>Consistency loss on validated pixels:</p>
  <p class="math">\( \mathcal{L}_{\text{consistency}} = \frac{1}{|\mathcal{V}|} \sum_{(p,q) \in \mathcal{V}} \|\hat{y}_s(p,q) - \hat{y}_t(p,q)\|_2^2 \)</p>

  <h2>Dataset Details</h2>
  <h3>FoSSIL Datasets</h3>
  <table>
    <tr>
      <th scope="col">Dataset</th>
      <th scope="col">Description</th>
      <th scope="col">Download</th>
    </tr>
    <tr>
      <td>Med FoSSIL-Disjoint</td>
      <td>Disjoint classes & medical domains across sessions</td>
      <td><a href="https://zenodo.org/records/17218309" target="_blank">Zenodo</a></td>
    </tr>
    <tr>
      <td>Med FoSSIL-Mixed</td>
      <td>Classes & domains may reappear; multi-domain per session</td>
      <td><a href="https://zenodo.org/records/17297404" target="_blank">Zenodo</a></td>
    </tr>
    <tr>
      <td>Med Semi-Supervised-FoSSIL</td>
      <td>Incremental classes with unlabeled data</td>
      <td><a href="https://zenodo.org/records/17218309" target="_blank">Zenodo</a></td>
    </tr>
    <tr>
      <td>Natural-FoSSIL</td>
      <td>Multiple driving domains; class-incremental & FSCIL</td>
      <td><a href="https://zenodo.org/records/17255889" target="_blank">Zenodo</a></td>
    </tr>
    <tr>
      <td>Semi-Supervised Natural-FoSSIL</td>
      <td>Incremental classes with unlabeled data</td>
      <td><a href="https://zenodo.org/records/17255889" target="_blank">Zenodo</a></td>
    </tr>
    <tr>
      <td>Detection</td>
      <td>Multi-domain COCO-O dataset for detection</td>
      <td><a href="https://drive.google.com/file/d/1aBfIJN0zo_i80Hv4p7Ch7M8pRzO37qbq/view?usp=drive_link" target="_blank">Google Drive</a></td>
    </tr>
  </table>

  <h3>Incremental Sessions</h3>
  <table>
    <tr>
      <th>Setting</th>
      <th>Session 0 (Base)</th>
      <th>Session 1</th>
      <th>Session 2</th>
      <th>Session 3</th>
      <th>Session 4</th>
      <th>Session 5</th>
    </tr>
    <tr>
      <td>Med FoSSIL-Disjoint</td>
      <td>15 (TS)</td>
      <td>5 (AMOS)</td>
      <td>6 (BCV)</td>
      <td>4 (MOTS)</td>
      <td>3 (BraTS)</td>
      <td>4 (VerSe)</td>
    </tr>
    <tr>
      <td>Med FoSSIL-Mixed</td>
      <td>10 (AMOS)</td>
      <td>8 (BCV, MOTS)</td>
      <td>6 (TS, AMOS)</td>
      <td>4 (MOTS, TS)</td>
      <td>7 (BraTS, VerSe)</td>
      <td>--</td>
    </tr>
    <tr>
      <td>Med SS-FoSSIL</td>
      <td>15 (TS)</td>
      <td>5 (AMOS)</td>
      <td>6 (BCV)</td>
      <td>4 (MOTS)</td>
      <td>3 (BraTS)</td>
      <td>4 (VerSe)</td>
    </tr>
    <tr>
      <td>Natural-FoSSIL</td>
      <td>10 (BDD)</td>
      <td>5 (IDD)</td>
      <td>5 (BDD, IDD)</td>
      <td>--</td>
      <td>--</td>
      <td>--</td>
    </tr>
    <tr>
      <td>SS Natural-FoSSIL</td>
      <td>10 (BDD)</td>
      <td>2 (Cityscapes)</td>
      <td>2 (IDD)</td>
      <td>3 (IDD)</td>
      <td>--</td>
      <td>--</td>
    </tr>
  </table>

  <hr>

  <h2>Baselines</h2>

  <h3>Class-Incremental Semantic Segmentation</h3>
  <ul>
    <li><a href="https://github.com/fcdl94/MiB">MiB</a>: A class-incremental learning method for semantic segmentation in natural images.</li>
    <li><a href="https://github.com/MrGiovanni/ContinualLearning">CLIP-CT</a>: A continual learning method for abdominal <em>multi-organ</em> and <em>tumour segmentation</em>.</li>
    <li><a href="https://github.com/jinpeng0528/STAR">Saving100x</a>: Leverages <em>prototype replay</em> for incremental semantic segmentation.</li>
    <li><a href="https://github.com/zhu-gl-ux/Adapter">Adaptive Prototype</a>: Updates <em>prototypes</em> adaptively for class-incremental learning.</li>
  </ul>
  <p class="note">These methods cannot handle few-shot learning and domain shifts.</p>

  <h3>Domain-Incremental Learning</h3>
  <ul>
    <li><a href="https://github.com/prachigarg23/MDIL-SS">MDIL</a>: Uses multiple decoders for different domains with a shared encoder.</li>
  </ul>
  <p class="note">Separate decoder per domain limits scalability; cannot handle few-shot incremental classes.</p>

  <h3>Few-shot Class-Incremental Learning</h3>
  <ul>
    <li><a href="https://github.com/fcdl94/FSS">PIFS</a>: Prototype-based few-shot CIL.</li>
    <li><a href="https://github.com/feyzaakyurek/subspace-reg">Subspace</a>: Regularization-based few-shot CIL.</li>
    <li><a href="https://github.com/IBM/constrained-FSCIL">C-FSCIL</a>: Meta-learning for few-shot CIL.</li>
    <li><a href="https://github.com/LAMDA-CL/CVPR22-Fact">FACT</a>: Reserves embedding space for new classes.</li>
    <li><a href="https://github.com/NeuralCollapseApplications/FSCIL">NC-FSCIL</a>: Fixes classifier as simplex ETF (Zhong et al.)</li>
    <li><a href="https://github.com/mobaidoctor/med-ddpm">Gen-Replay</a>: Data-free replay using diffusion model for 3D volumes.</li>
    <li><a href="https://github.com/RogerQi/GAPS">GAPS</a>: Guided copy-paste augmentation.</li>
    <li><a href="https://github.com/ihaeyong/SoftNet-FSCIL">SoftNet</a>: Learns model weights & adaptive soft masks.</li>
    <li><a href="https://github.com/ChasonJiang/FSCILSS">FSCIL-SS</a>: Pseudo-labeling & knowledge distillation.</li>
    <li><a href="https://github.com/dipamgoswami/FeCAM">FeCAM</a>: Enhances class prototype representation; evaluates domain-incremental learning separately.</li>
  </ul>
  <p class="note">These methods cannot handle domain shifts jointly with class-incremental and few-shot learning.</p>

  <h3>Semi-Supervised Based Methods</h3>
  <ul>
    <li><a href="https://github.com/decile-team/cords">RETRIEVE</a>: Robust semi-supervised learning via coreset selection.</li>
    <li><a href="https://github.com/kangzhiq/NNCSL">NNCSL</a>: Nearest-neighbor based continual semi-supervised learning.</li>
    <li><a href="https://github.com/yawencui/UaD-ClE">UaD-CE</a>: Class Equilibrium + Uncertainty-aware Distillation.</li>
    <li><a href="https://github.com/PanLiuCSU/CSL">CSL</a>: Pseudo-label selection as convex optimization.</li>
  </ul>
  <p class="note">Cannot jointly address domain shifts, class-incremental, and few-shot learning.</p>

  <h3>Others (Representation Learning, Few-shot Learning, Meta-Learning, Active Learning, Domain-shift)</h3>
  <ul>
    <li><a href="https://github.com/google-research/google-research/tree/master/supcon">SupCL</a>, <a href="https://github.com/google-research/simclr">UnSupCL</a>, <a href="https://github.com/joshr17/HCL">UnSupCL-HNM</a>: Contrastive learning methods.</li>
    <li><a href="https://github.com/AI-secure/multi-task-learning">MTL</a>: Fast adaptation to unseen tasks; few-shot learning.</li>
    <li><a href="https://github.com/CEA-LIST/MetaMTReg">MAML</a>: Multi-task representation learning; few-shot learning.</li>
    <li><a href="https://github.com/ljwztc/CLIP-Driven-Universal-Model">CLIP-driven</a>: Language-Vision model for organ segmentation & tumor detection.</li>
    <li><a href="https://github.com/paolomandica/HALO">HALO</a>: Hyperbolic NN for pixel-level active learning under domain shift.</li>
  </ul>

</body>
</html>
