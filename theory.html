<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Theoretical Analysis of Guided Noise Injection (GNI)</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.min.js"></script>
    <style>
        body {
            font-family: 'Georgia', serif;
            line-height: 1.6;
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f9f9f9;
            color: #333;
        }
        h1 {
            color: #2c3e50;
            border-bottom: 3px solid #3498db;
            padding-bottom: 10px;
        }
        h2 {
            color: #34495e;
            margin-top: 30px;
            border-bottom: 2px solid #95a5a6;
            padding-bottom: 5px;
        }
        h3 {
            color: #555;
            margin-top: 25px;
        }
        h4 {
            color: #666;
            margin-top: 20px;
            font-style: italic;
        }
        .definition, .theorem, .proof, .assumption {
            background-color: #fff;
            border-left: 4px solid #3498db;
            padding: 15px;
            margin: 20px 0;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .theorem {
            border-left-color: #e74c3c;
        }
        .proof {
            border-left-color: #2ecc71;
        }
        .assumption {
            border-left-color: #f39c12;
        }
        .definition-title, .theorem-title, .proof-title, .assumption-title {
            font-weight: bold;
            margin-bottom: 10px;
        }
        ul {
            margin: 15px 0;
        }
        li {
            margin: 8px 0;
        }
        .note {
            background-color: #fff3cd;
            border-left: 4px solid #ffc107;
            padding: 10px;
            margin: 15px 0;
        }
        .mjx-chtml {
            font-size: 110% !important;
        }
    </style>
</head>
<body>

<h1>Theoretical Analysis of Guided Noise Injection (GNI)</h1>

<h2>1. Definitions, Notation, and Assumptions</h2>

<div class="definition">
    <div class="definition-title">Definition 1 (Weight vector)</div>
    Let \(\mathbb{W} \in \mathbb{R}^p\) denote the flattened vector containing all model parameters, where each component is indexed by \(i \in \{1, \dots, p\}\), and \(w_i\) denotes the \(i\)-th parameter.
</div>

<div class="definition">
    <div class="definition-title">Definition 2 (Gradient buffer)</div>
    At the current optimization step,
    \[
    g_i = \frac{\partial \mathcal{L}}{\partial w_i},
    \]
    denote the gradient of the loss \(\mathcal{L}\) w.r.t. \(w_i\), and define the elementwise squared gradient:
    \[
    G_i = g_i^2.
    \]
</div>

<div class="definition">
    <div class="definition-title">Definition 3 (Inverse gradient modulator (normalized))</div>
    Introduce a stable inverse-gradient modulator:
    \[
    G_{\mathrm{inv},i} = \frac{1}{G_i + \varepsilon}, \quad \varepsilon > 0,
    \]
    and normalize to a bounded range to control noise magnitude:
    \[
    \tilde{G}_{i} = \frac{1 + G_{\mathrm{inv},i} - \min_j G_{\mathrm{inv},j}}{1 + \max_j G_{\mathrm{inv},j} - \min_j G_{\mathrm{inv},j}} \in (0,1].
    \]
</div>

<div class="definition">
    <div class="definition-title">Definition 4 (Guided noise operator)</div>
    Let \(\xi = (\xi_1,\dots,\xi_p)\) be i.i.d. standard Gaussian noise, \(\xi_i \sim \mathcal{N}(0,1)\). Define,
    \[
    \mathcal{U}(\mathbb{W}) = \mathbb{W} + \tilde{G} \odot \xi,
    \]
    i.e., componentwise:
    \[
    \widetilde{w}_i = w_i + \tilde{G}_i \, \xi_i.
    \]
</div>

<div class="assumption">
    <div class="assumption-title">Assumption 1 (Smoothness)</div>
    \(\mathcal{L}: \mathbb{R}^p \to \mathbb{R}\) is twice continuously differentiable in a neighborhood of \(\mathbb{W}\). Let \(g=(g_1,\dots,g_p)\) be the gradient vector and \(H = \nabla^2 \mathcal{L}(\mathbb{W})\) the Hessian.
</div>

<h2>2. Expected Perturbed Loss</h2>

<p>Consider the Taylor expansion of \(\mathcal{L}\) at \(\mathbb{W}\) with increment \(\Delta \mathbb{W} = \tilde{G} \odot \xi\):</p>
\[
\mathcal{L}(\mathbb{W} + \Delta \mathbb{W}) = \mathcal{L}(\mathbb{W}) + g^\top \Delta \mathbb{W} + \frac{1}{2} \Delta \mathbb{W}^\top H \Delta \mathbb{W} + R_3(\Delta \mathbb{W}),
\]
<p>where \(R_3(\Delta \mathbb{W}) = O(\|\Delta \mathbb{W}\|^3)\).</p>

<h4>Linear term expectation:</h4>
\[
\mathbb{E}_\xi[g^\top \Delta \mathbb{W}] = \sum_i g_i \tilde{G}_i \mathbb{E}[\xi_i] = 0,
\]
<p>since \(\mathbb{E}[\xi_i] = 0\).</p>

<h4>Quadratic term expectation (diagonal approximation):</h4>
\[
\frac{1}{2} \mathbb{E}_\xi[\Delta \mathbb{W}^\top H \Delta \mathbb{W}]
= \frac{1}{2} \sum_{i,j} H_{ij} \tilde{G}_i \tilde{G}_j \mathbb{E}[\xi_i \xi_j]
\approx \frac{1}{2} \sum_{i=1}^p H_{ii} \tilde{G}_i^2,
\]
<p>because \(\mathbb{E}[\xi_i \xi_j] = 0\) for \(i\neq j\) and \(\mathbb{E}[\xi_i^2] = 1\).</p>

<h4>Higher order term:</h4>
\[
|R_3(\Delta \mathbb{W})| \le C \|\Delta \mathbb{W}\|^3, \quad \mathbb{E}[|R_3|] = O(\mathbb{E}\|\Delta \mathbb{W}\|^3) = O(\max_i \tilde{G}_i^3),
\]
<p>for some constant \(C\). Since \(\tilde{G}_i \in (0,1]\), the higher order term is bounded even for small \(g_i^2\).</p>

<div class="note">
    <strong>Note:</strong> For additional control of noise magnitude during training, one can scale the modulators by a factor 
    \(\alpha \in (0,1]\):
    \[
    \tilde{G}_i \;\longrightarrow\; \alpha \, \tilde{G}_i.
    \]
    With \(\Delta\mathbb{W}=\alpha\tilde{G}\odot\xi\) and \(\xi\sim\mathcal{N}(0,I_p)\) this yields,
    \[
    |R_3(\alpha\tilde{G}\odot\xi)| \le C(\alpha\max_i\tilde{G}_i)^3\|\xi\|^3,
    \]
    and thus, taking expectation,
    \[
    \mathbb{E}\big[|R_3(\alpha\tilde{G}\odot\xi)|\big] \le C(\alpha\max_i\tilde{G}_i)^3\mathbb{E}\|\xi\|^3
    = O\!\big((\alpha\max_i\tilde{G}_i)^3\big).
    \]
    The factor \(\mathbb{E}\|\xi\|^3\) is finite (depends only on model parameters \(p\)).
    This ensures that the higher-order contributions remain bounded and controllable, while providing finer control of noise injection.
</div>

<p>Thus, expected perturbed loss:</p>
\[
\mathbb{E}_\xi[\mathcal{L}(\mathcal{U}(\mathbb{W}))]
= \mathcal{L}(\mathbb{W}) + \frac{1}{2} \sum_{i=1}^p H_{ii} \tilde{G}_i^2 + O(\max_i \tilde{G}_i^3)
\]

<h3>2.1 Interpretation and Theoretical Motivation</h3>

<ul>
    <li>\(\tilde{G}_i\) is large for low-gradient coordinates (\(g_i^2\) small), injecting more noise along flat directions (directions of low curvature) of the loss landscape.</li>
    <li>\(\tilde{G}_i\) is small for high-gradient coordinates, suppressing perturbation along sensitive directions.</li>
    <li>The bounded normalization ensures that all \(\tilde{G}_i \le 1\), bounding the perturbation magnitude even when gradients are arbitrarily small, thus controlling the higher-order terms.</li>
    <li>Hence, GNI selectively perturbs parameters along directions of low sensitivity, promoting exploration along flat regions without significantly increasing expected loss.</li>
    <li>This justifies theoretically why GNI can encourage flatter minima, better generalization, and robust optimization behavior.</li>
</ul>

<h2>3. Spectral Viewpoint: Hessian Eigen-structure</h2>

<p>Let \(H = U \Lambda U^\top\) be the eigendecomposition of the Hessian, where \(U\) is orthonormal and \(\Lambda = \mathrm{diag}(\lambda_1,\dots,\lambda_p)\). Then each diagonal entry satisfies,</p>
\[
H_{ii} = \sum_{r=1}^p \lambda_r u_{ir}^2.
\]

<p>The expected second-order contribution with \(\tilde{G}\) becomes,</p>
\[
\sum_{i=1}^p H_{ii} \tilde{G}_i^2 = \sum_{i=1}^p \sum_{r=1}^p \lambda_r u_{ir}^2 \tilde{G}_i^2 = \sum_{r=1}^p \lambda_r \sum_{i=1}^p (u_{ir} \tilde{G}_i)^2.
\]

<p>Define \(v^{(r)} \in \mathbb{R}^p\) with components \(v_i^{(r)} = u_{ir} \tilde{G}_i\). Then,</p>
\[
\sum_{i=1}^p H_{ii} \tilde{G}_i^2 = \sum_{r=1}^p \lambda_r \|v^{(r)}\|_2^2 = \sum_{r=1}^p \lambda_r \|U_{:,r} \odot \tilde{G}\|_2^2
\]

<h3>3.1 Interpretation</h3>

<p>GNI implements <em>anisotropic noise injection</em>: each Hessian eigenvalue \(\lambda_r\) is weighted by \(\|u^{(r)} \odot \tilde{G}\|_2^2\), the squared \(\ell_2\)-norm of \(\tilde{G}\) along the \(r\)-th eigendirection. When \(\tilde{G}\) is large on coordinates aligned with low-curvature directions (small \(\lambda_r\)), the noise contribution \(\lambda_r \|u^{(r)} \odot \tilde{G}\|_2^2\) remains controlled by the small eigenvalue; conversely, high-curvature directions (large \(\lambda_r\)) are automatically protected because \(\tilde{G}\) is small there. This concentrates noise along flat directions with minimal loss impact while protecting sensitive directions, encouraging flatter minima that improve generalization, with higher-order terms remaining bounded even when gradients vanish.</p>

<h1>PAC-Bayes Analysis of Guided Noise Injection</h1>

<h2>4. Setup and Assumptions</h2>

<p>We interpret the guided noise injection (GNI),</p>
\[
\widetilde{\mathbb{W}} = \mathbb{W} + \tilde{G} \odot \xi, 
\qquad \xi \sim \mathcal{N}(0, I_p),
\]
<p>as defining a stochastic posterior over parameters, where \(\mathbb{W} \in \mathbb{R}^p\) denotes the current model weights. Each coordinate \(w_i\) is perturbed by scaled Gaussian noise \(\tilde{G}_i \xi_i\), with normalized noise magnitude,</p>
\[
\tilde{G}_i = \frac{1 + G_{\mathrm{inv},i} - \min_j G_{\mathrm{inv},j}}{1 + \max_j G_{\mathrm{inv},j} - \min_j G_{\mathrm{inv},j}} \in (0,1],
\qquad
G_{\mathrm{inv},i} = \frac{1}{(\nabla_{w_i} \mathcal{L})^2 + \varepsilon}
\]

<p><strong>Assumptions:</strong></p>
<ul>
    <li>The coordinates of \(\widetilde{\mathbb{W}}\) are independent, yielding a diagonal posterior covariance.</li>
    <li>Larger \(\tilde{G}_i\) corresponds to low-sensitivity directions (smaller gradient magnitude).</li>
    <li>The prior is isotropic Gaussian: \(p(\theta) = \mathcal{N}(0, \tau^2 I_p)\), and the posterior induced by GNI is \(q(\theta) = \mathcal{N}(\mathbb{W}, \Sigma_q)\) with diagonal covariance \(\Sigma_q = \mathrm{diag}(\tilde{G}_1^2, \dots, \tilde{G}_p^2)\).</li>
</ul>

<h2>5. KL Divergence Between Posterior and Prior</h2>

<p>For general multivariate Gaussians \(q = \mathcal{N}(\mu_q, \Sigma_q)\) and \(p = \mathcal{N}(\mu_p, \Sigma_p)\), the KL divergence is:</p>
\[
\mathrm{KL}(q\|p) = \frac{1}{2} \Big[ 
\mathrm{tr}(\Sigma_p^{-1} \Sigma_q) + (\mu_p - \mu_q)^\top \Sigma_p^{-1} (\mu_p - \mu_q) - p + \ln \frac{\det \Sigma_p}{\det \Sigma_q} 
\Big].
\]

<p>For the GNI posterior \(q(\theta) = \mathcal{N}(\mathbb{W}, \mathrm{diag}(\tilde{G}_1^2, \dots, \tilde{G}_p^2))\) and isotropic prior \(p(\theta) = \mathcal{N}(0, \tau^2 I_p)\), we have:</p>

<ul>
    <li>Posterior (GNI): \(\mu_q = \mathbb{W} = (w_1, \dots, w_p),\quad \Sigma_q = \mathrm{diag}(\tilde{G}_1^2, \dots, \tilde{G}_p^2)\),</li>
    <li>Prior: \(\mu_p = 0, \quad \Sigma_p = \tau^2 I_p\) (isotropic).</li>
</ul>

<h4>Trace term: \(\mathrm{tr}(\Sigma_p^{-1} \Sigma_q)\)</h4>

<p>Since \(\Sigma_p = \tau^2 I_p\) and \(\Sigma_q = \mathrm{diag}(\tilde{G}_1^2, \dots, \tilde{G}_p^2)\):</p>
\[
\Sigma_p^{-1} \Sigma_q = (\tau^2 I_p)^{-1} \mathrm{diag}(\tilde{G}_1^2, \dots, \tilde{G}_p^2)
= \frac{1}{\tau^2} \mathrm{diag}(\tilde{G}_1^2, \dots, \tilde{G}_p^2).
\]
<p>The trace of a diagonal matrix is the sum of its diagonal elements, so</p>
\[
\mathrm{tr}(\Sigma_p^{-1} \Sigma_q) = \sum_{i=1}^p \frac{\tilde{G}_i^2}{\tau^2}.
\]

<h4>Mean difference term: \((\mu_p - \mu_q)^\top \Sigma_p^{-1} (\mu_p - \mu_q)\)</h4>

\[
(\mu_p - \mu_q)^\top \Sigma_p^{-1} (\mu_p - \mu_q) = (0 - \mathbb{W})^\top (\tau^{-2} I_p) (0 - \mathbb{W})
= \frac{1}{\tau^2} \sum_{i=1}^p w_i^2.
\]

<p>This term measures how far the posterior mean \(\mathbb{W}\) is from the prior mean \(0\), scaled by the prior variance.</p>

<h4>Log-determinant term: \(\ln \frac{\det \Sigma_p}{\det \Sigma_q}\)</h4>

<p>The determinant of a matrix is the product of its eigenvalues. For a diagonal matrix, the eigenvalues are the diagonal entries:</p>
\[
\det(\mathrm{diag}(d_1, \dots, d_p)) = \prod_{i=1}^p d_i.
\]

<p>Hence,</p>
\[
\det \Sigma_p = \det(\tau^2 I_p) = (\tau^2)^p, \quad
\det \Sigma_q = \det(\mathrm{diag}(\tilde{G}_1^2, \dots, \tilde{G}_p^2)) = \prod_{i=1}^p \tilde{G}_i^2.
\]

<p>Then the log-determinant term becomes,</p>
\[
\ln \frac{\det \Sigma_p}{\det \Sigma_q} = \ln \frac{\tau^{2p}}{\prod_{i=1}^p \tilde{G}_i^2} = \sum_{i=1}^p \ln \frac{\tau^2}{\tilde{G}_i^2}.
\]

<p>This term penalizes how much the posterior <em>volume</em> differs from the prior. If posterior variance is smaller than prior, the log term is positive.</p>

<ul>
    <li>\(\frac{\tilde{G}_i^2}{\tau^2}\) → contribution from posterior variance</li>
    <li>\(\frac{w_i^2}{\tau^2}\) → contribution from posterior mean</li>
    <li>\(-\ln(\tilde{G}_i^2/\tau^2)\) → penalizes shrinkage or expansion of posterior volume</li>
</ul>

<p>Combining these, the KL divergence reduces to:</p>
\[
\mathrm{KL}(q\|p) = \frac{1}{2} \sum_{i=1}^{p} \Big[ \frac{\tilde{G}_i^2}{\tau^2} + \frac{w_i^2}{\tau^2} - 1 - \ln \frac{\tilde{G}_i^2}{\tau^2} \Big].
\tag{1}
\]

<h2>6. Interpretation of the KL Divergence Term</h2>

<p>Each parameter \(w_i\) contributes to the KL divergence:</p>
\[
\mathrm{KL}_i = \frac{1}{2} \Big[ \frac{\tilde{G}_i^2}{\tau^2} + \frac{w_i^2}{\tau^2} - 1 - \ln \frac{\tilde{G}_i^2}{\tau^2} \Big].
\]

<p>Define,</p>
\[
x_i = \frac{\tilde{G}_i^2}{\tau^2}, \qquad f(x) = \frac{1}{2}(x - \ln x - 1),
\]
<p>so that,</p>
\[
\mathrm{KL}_i = f(x_i) + \frac{w_i^2}{2\tau^2}.
\tag{2}
\]

<h4>Low-gradient parameters:</h4>
<p>Parameters with small gradients have large \(\tilde{G}_i\), injecting more noise. This increases posterior variance in low-sensitivity directions, <strong>promoting exploration and regularization</strong>, allowing these parameters to safely explore flat regions without significantly affecting expected loss. The KL contribution is influenced both by the noise scale \(\tilde{G}_i^2/\tau^2\) and the weight magnitude \(w_i^2/\tau^2\). Since \(\tilde{G}_i \in (0,1]\), choosing \(\tau \in [\tilde{G}_{\min}, \tilde{G}_{\max}]\) ensures \(x_i\) remains bounded, preventing the KL from growing excessively.</p>

<h4>High-gradient parameters:</h4>
<p>Parameters with large gradients have small \(\tilde{G}_i\), suppressing noise. The KL term is then dominated by \(w_i^2/\tau^2\), reflecting that the posterior is tightly concentrated around the current weight, which <strong>prevents drift of these important weight parameters</strong>. The normalization in GNI ensures \(\tilde{G}_i > 0\), preventing the log term from diverging. Intuitively, high-gradient parameters remain stable.</p>

<p>Thus, the KL contribution reflects both the posterior spread (\(\tilde{G}_i\)) and the weight magnitude (\(w_i\)), providing a principled trade-off between stochastic regularization and posterior concentration. This provides a rigorous, <em>anisotropic</em> regularization mechanism that adapts to the local geometry of the loss landscape.</p>

<div class="theorem">
    <div class="theorem-title">Theorem 1 (PAC-Bayes Bound Improvement via GNI)</div>
    Let \(p(\theta)\) denote a prior over model parameters, and let \(q_{\mathrm{ani}}(\theta)\) and \(q_{\mathrm{iso}}(\theta)\) denote the anisotropic and isotropic posteriors, respectively, both having the same total variance. Then, the anisotropic posterior induced by Guided Noise Injection (GNI) achieves a tighter PAC-Bayes bound than the isotropic posterior:
    \[
    \mathcal{L}_{\mathrm{PAC}}(q_{\mathrm{ani}}(\theta), p(\theta)) \le \mathcal{L}_{\mathrm{PAC}}(q_{\mathrm{iso}}(\theta), p(\theta))
    \]
</div>

<div class="proof">
    <div class="proof-title">Proof:</div>
    
    <p>We define two posterior distributions over parameters \(\theta\):</p>
    
    <ul>
        <li><strong>Anisotropic posterior (GNI)</strong>:
        \[
        q_{\mathrm{ani}}(\theta) = \mathcal{N}(\mathbb{W}, \Sigma_{\mathrm{ani}}), 
        \quad \Sigma_{\mathrm{ani}} = \mathrm{diag}(\tilde{G}_1^2, \dots, \tilde{G}_p^2),
        \]
        where \(\tilde{G}_i \in (0,1]\) is an adaptive variance, decreasing with gradient magnitude \(|\nabla_{w_i}\mathcal{L}|\):
        \[
        |\nabla_{w_i}\mathcal{L}| \text{ small} \Rightarrow \tilde{G}_i \text{ large},\quad
        |\nabla_{w_i}\mathcal{L}| \text{ large} \Rightarrow \tilde{G}_i \text{ small}.
        \]
        </li>
        
        <li><strong>Isotropic posterior</strong>:
        \[
        q_{\mathrm{iso}}(\theta) = \mathcal{N}(\mathbb{W}, \sigma^2 I_p),
        \]
        with \(\sigma^2 = \frac{1}{p} \sum_{i=1}^p \tilde{G}_i^2\) chosen so that the total variance matches that of the anisotropic posterior:
        \[
        \mathrm{tr}(\Sigma_{\mathrm{ani}}) = \mathrm{tr}(\sigma^2 I_p) = p\sigma^2.
        \]
        </li>
    </ul>
    
    <p>The prior is isotropic Gaussian:</p>
    \[
    p(\theta) = \mathcal{N}(0, \tau^2 I_p), \quad \tau>0.
    \]
    
    <p>Using Equation (1), for the isotropic posterior with variance \(\sigma^2\):</p>
    \[
    \mathrm{KL}(q_{\mathrm{iso}} \| p) = \frac{1}{2} \sum_{i=1}^p \left[ \frac{\sigma^2}{\tau^2} + \frac{w_i^2}{\tau^2} - 1 - \ln \frac{\sigma^2}{\tau^2} \right]
    = \frac{1}{2} \left[ \frac{p \sigma^2}{\tau^2} + \frac{\|\mathbb{W}\|_2^2}{\tau^2} - p - p \ln \frac{\sigma^2}{\tau^2} \right].
    \tag{3}
    \]
    
    <p>Similar to Equation (2),</p>
    \[
    \mathrm{KL}^{\mathrm{iso}}_i = f(y_i) + \frac{w_i^2}{2\tau^2}.
    \tag{4}
    \]
    <p>where,</p>
    \[
    y_i = \frac{\sigma^2}{\tau^2} \quad \forall i.
    \]
    
    <p>Using a second-order Taylor expansion around \(\mathbb{W}\):</p>
    \[
    \mathcal{L}(\theta) \approx \mathcal{L}(\mathbb{W}) + (\theta - \mathbb{W})^\top \nabla \mathcal{L}(\mathbb{W}) + \frac{1}{2} (\theta - \mathbb{W})^\top H (\theta - \mathbb{W}),
    \]
    <p>where,</p>
    \[
    H = \nabla^2_{\mathbb{W}} \mathcal{L}(\mathbb{W}) = U \Lambda U^\top, 
    \quad \Lambda = \mathrm{diag}(\lambda_1,\dots,\lambda_p), \quad U^\top U = I_p.
    \]
    
    <p>Taking expectation under \(q(\theta)\) and using \(\mathbb{E}_{q}[\theta - \mathbb{W}] = 0\):</p>
    \[
    \mathbb{E}_{\theta \sim q}[\mathcal{L}(\theta)] \approx \mathcal{L}(\mathbb{W}) + \frac{1}{2} \mathrm{tr}(H \Sigma_q).
    \tag{5}
    \]
    
    <p>For anisotropic posterior:</p>
    \[
    \mathbb{E}_{q_{\mathrm{ani}}}[\mathcal{L}(\theta)] - \mathcal{L}(\mathbb{W}) \approx \frac{1}{2} \mathrm{tr}(H \Sigma_{\mathrm{ani}}) = \frac{1}{2} \sum_{i=1}^p H_{ii} \tilde{G}_i^2,
    \]
    \[
    \sum_{i=1}^p H_{ii} \tilde{G}_i^2 
    = \sum_{i=1}^p \sum_{r=1}^p \lambda_r u_{ir}^2 \tilde{G}_i^2 
    = \sum_{r=1}^p \lambda_r \sum_{i=1}^p (u_{ir} \tilde{G}_i)^2
    = \sum_{r=1}^p \lambda_r \| U_{:,r} \odot \tilde{G} \|_2^2
    \]
    
    <p>For isotropic posterior:</p>
    \[
    \mathbb{E}_{q_{\mathrm{iso}}}[\mathcal{L}(\theta)] - \mathcal{L}(\mathbb{W}) \approx \frac{1}{2} \mathrm{tr}(H \Sigma_{\mathrm{iso}}) = \frac{1}{2} \sum_{i=1}^p H_{ii} \sigma^2 = \frac{1}{2} \sigma^2 \mathrm{tr}(H),
    \]
    \[
    \sigma^2 \mathrm{tr}(H) = \sigma^2 \sum_{i=1}^p H_{ii} = \sigma^2 \sum_{r=1}^p \lambda_r.
    \]
    
    <p>Low-curvature directions (\(\lambda_r\) small) are allowed larger variance \(\tilde{G}_i \in (0,1]\), contributing minimally to \(\sum_{r=1}^p \lambda_r \| U_{:,r} \odot \tilde{G} \|_2^2\).
    High-curvature directions (\(\lambda_r\) large) have small \(\tilde{G}_i\), preventing large expected loss increase.
    Isotropic variance \(\sigma^2\) does not adapt to curvature; high-curvature directions may receive excessive noise.</p>
    
    <p>Hence, we obtain the inequality</p>
    \[
    \mathbb{E}_{\theta \sim q_{\mathrm{ani}}}[\mathcal{L}(\theta)] 
    = \mathcal{L}(\mathbb{W}) + \frac{1}{2} \mathrm{tr}(H \Sigma_{\mathrm{ani}})
    \le \mathcal{L}(\mathbb{W}) + \frac{1}{2} \mathrm{tr}(H \Sigma_{\mathrm{iso}})
    = \mathbb{E}_{\theta \sim q_{\mathrm{iso}}}[\mathcal{L}(\theta)].
    \tag{6}
    \]
    
    <p>The KL divergence term satisfies convexity property of \(f(x) = x - \ln x - 1\):</p>
    \[
    \frac{1}{p} \sum_{i=1}^p f\Big(\frac{\tilde{G}_i^2}{\tau^2}\Big) \le f\Big(\frac{1}{p} \sum_{i=1}^p \frac{\tilde{G}_i^2}{\tau^2} \Big) = f\Big(\frac{\sigma^2}{\tau^2}\Big),
    \]
    <p>by Jensen's inequality. Hence,</p>
    \[
    \sum_{i=1}^p f\Big(\frac{\tilde{G}_i^2}{\tau^2}\Big) \le p f\Big(\frac{\sigma^2}{\tau^2}\Big).
    \tag{7}
    \]
    
    <p>The mean term \(\sum_i w_i^2/(2\tau^2)\) is identical for both posteriors (weight normalization ensures boundedness). Therefore, from Equation (2) and (4):</p>
    \[
    \mathrm{KL}(q_{\mathrm{ani}} \| p) \le \mathrm{KL}(q_{\mathrm{iso}} \| p).
    \tag{8}
    \]
    
    <p>For dataset size \(N\) and confidence level \(\delta \in (0,1)\), with probability at least \(1-\delta\), the PAC-Bayes bound states:</p>
    \[
    \mathbb{E}_{\theta \sim q}[\mathcal{L}_{\mathrm{test}}(\theta)]
    \le
    \mathbb{E}_{\theta \sim q}[\widehat{\mathcal{L}}(\theta)]
    + \sqrt{\frac{\mathrm{KL}(q\|p) + \ln\frac{N}{\delta}}{2(N-1)}}.
    \tag{9}
    \]
    
    <p>Combining (6) and (8):</p>
    \[
    \mathbb{E}_{q_{\mathrm{ani}}}[\mathcal{L}_{\mathrm{test}}] 
    \le \mathbb{E}_{q_{\mathrm{ani}}}[\widehat{\mathcal{L}}(\theta)] + \sqrt{\frac{\mathrm{KL}(q_{\mathrm{ani}}\|p)+\ln(N/\delta)}{2(N-1)}} 
    \le \mathbb{E}_{q_{\mathrm{iso}}}[\widehat{\mathcal{L}}(\theta)] + \sqrt{\frac{\mathrm{KL}(q_{\mathrm{iso}}\|p)+\ln(N/\delta)}{2(N-1)}},
    \]
    
    \[
    \implies
    \mathcal{L}_{\mathrm{PAC}}(q_{\mathrm{ani}}(\theta), p(\theta)) \le \mathcal{L}_{\mathrm{PAC}}(q_{\mathrm{iso}}(\theta), p(\theta)).
    \]
    
    <p><em>Thus, the anisotropic posterior induced by GNI achieves a tighter PAC-Bayes bound than the isotropic posterior with matched total variance.</em></p>
</div>

<h1>Theoretical Analysis of Prototype-Guided Pseudo-Label Refinement (PRL)</h1>

<h2>7. Setup</h2>

<p>Consider a student-teacher semi-supervised segmentation framework:</p>

<ul>
    <li>Labeled dataset: \(\mathcal{D}_l\),</li>
    <li>Unlabeled dataset: \(\mathcal{D}_u\),</li>
    <li>Student network: \(M_s\), Teacher network: \(M_t\) (EMA of \(M_s\)),</li>
    <li>Pseudo-label weight: \(\gamma \in (0,1)\),</li>
    <li>Exponential Moving Average (EMA) decay: \(\alpha \in [0,1)\),</li>
</ul>

<p>Let \(\epsilon_0\) denote the base error of the student on labeled data. For unlabeled data, let \(\epsilon_s(t)\) and \(\epsilon_t(t)\) denote the fraction of incorrect pseudo-labels for the student and teacher at iteration \(t\).</p>

<h2>8. Pseudo-Label Error Dynamics without Pseudo-Label Refinement</h2>

<p>We begin by formulating the coupled dynamics between the student and teacher networks in the absence of pseudo-label refinement (PRL). Let \(\epsilon_s(t)\) and \(\epsilon_t(t)\) denote the expected pseudo-label errors (i.e., the fractions of incorrect pseudo-labels) produced by the student and teacher, respectively, at iteration \(t\). The student updates its parameters using a mixture of ground-truth labeled data and teacher-generated pseudo-labels:</p>
\[
\epsilon_s(t+1) = (1-\gamma)\,\epsilon_0 + \gamma\,\epsilon_t(t),
\tag{10}
\]
<p>where \(\epsilon_0\) represents the intrinsic baseline error arising from labeled supervision, and \(\gamma \in [0,1]\) controls the relative contribution of pseudo-labeled data in training. Intuitively, \(\gamma=0\) corresponds to purely supervised learning based solely on labeled data, whereas \(\gamma \to 1\) denotes a regime where training is dominated by pseudo-labels generated by the teacher.</p>

<p>The teacher, on the other hand, is an exponentially moving average (EMA) of the student:</p>
\[
\epsilon_t(t+1) = \alpha \epsilon_t(t) + (1-\alpha) \epsilon_s(t+1),
\tag{11}
\]
<p>where \(\alpha \in [0,1)\) is the EMA decay constant. This coupling forms a delayed feedback loop: the teacher smooths over the temporal trajectory of student errors.</p>

<p>Substituting Equation (10) into Equation (11) gives:</p>
\[
\epsilon_t(t+1)
= \alpha \epsilon_t(t) + (1-\alpha)\big[(1-\gamma)\epsilon_0 + \gamma \epsilon_t(t)\big]
= [\alpha + (1-\alpha)\gamma] \epsilon_t(t) + (1-\alpha)(1-\gamma)\epsilon_0.
\]
<p>This establishes a <em>non-homogeneous linear recurrence relation</em> describing how teacher error evolves in conjunction with student learning dynamics.</p>

<p>Let us define:</p>
\[
\lambda = \alpha + (1-\alpha)\gamma,
\]
<p>The update then simplifies to:</p>
\[
\epsilon_t(t+1) = \lambda \epsilon_t(t) + (1-\alpha)(1-\gamma)\epsilon_0
\]
<p>The general solution is:</p>
\[
\epsilon_t(t) = \lambda^t \epsilon_t(0) + (1-\alpha)(1-\gamma)\epsilon_0 \sum_{k=0}^{t-1}\lambda^k,
\]
<p>where \(\epsilon_t(0)\) denotes the initial teacher pseudo-label error at iteration \(t=0\).</p>

<p>The term \(\lambda^t \epsilon_t(0)\) captures the contribution of past errors, exponentially weighted over time, while the summation term captures the accumulation of newly introduced errors from labeled supervision.</p>

<p>We analyze three characteristic regimes of \(\lambda\):</p>

<p><strong>(a) \(\lambda < 1\):</strong><br>
The geometric series converges:
\[
\sum_{k=0}^{t-1}\lambda^k = \frac{1-\lambda^t}{1-\lambda} \xrightarrow[t\to\infty]{} \frac{1}{1-\lambda}.
\]
Therefore, the asymptotic value of the teacher error is:
\[
\epsilon_\infty = \frac{(1-\alpha)(1-\gamma)\epsilon_0}{1-\lambda}.
\tag{12}
\]
Substituting \(\lambda = \alpha + (1-\alpha)\gamma\), we find:
\[
\epsilon_\infty = \frac{(1-\alpha)(1-\gamma)\epsilon_0}{(1-\alpha)(1-\gamma)} = \epsilon_0.
\]
The teacher asymptotically retains the same error as if trained purely on ground-truth data.</p>

<p><strong>(b) \(\lambda = 1\):</strong><br>
The summation becomes divergent and grows linearly with time:
\[
\sum_{k=0}^{t-1}\lambda^k = t.
\]
The error therefore exhibits <em>linear drift</em>:
\[
\epsilon_t(t) = \epsilon_t(0) + (1-\alpha)(1-\gamma)\epsilon_0 \cdot t.
\]
Errors are neither damped nor amplified exponentially, but drift slowly.</p>

<p><strong>(c) \(\lambda > 1\):</strong><br>
The geometric series diverges exponentially:
\[
\epsilon_t(t) = \lambda^t \epsilon_t(0) + (1-\alpha)(1-\gamma)\epsilon_0 \frac{\lambda^t - 1}{\lambda - 1}.
\]
Here, \(\epsilon_t\) grows exponentially leading to <em>confirmation bias</em>. The erroneous pseudo-labels reinforce the teacher, which in turn produces even more erroneous labels. Such behavior is typical when \(\gamma\) is high (strong reliance on unlabeled data).</p>

<p>For bounded error propagation, we require \(\lambda < 1\), which simplifies to \(\gamma < 1\).
However, in real semi-supervised settings, \(|\mathcal{D}_u| \gg |\mathcal{D}_l|\), leading to an effective \(\gamma\) close to 1. This makes pseudo-label drift and error amplification inevitable without refinement mechanisms. This theoretical observation provides a direct justification for <em>pseudo-label filtering and refinement</em> strategies to maintain \(\lambda < 1\) in practice.</p>

<h2>9. Prototype-Guided Pseudo-Label Refinement</h2>

<p>Let \(z = f_\theta(x) \in \mathbb{R}^d\) denote the feature embedding of an unlabeled sample \(x\), where \(f_\theta\) is the student model with parameters \(\theta\). Let \(\mu_c \in \mathbb{R}^d\) be the prototype (mean feature) for class \(c\), computed from the labeled set \(\mathcal{D}_l^{(c)}\) of \(N_c\) examples of class \(c\):</p>
\[
\mu_c = \frac{1}{N_c} \sum_{x_i \in \mathcal{D}_l^{(c)}} f_\theta(x_i),
\]
<p>where \(\mathcal{D}_l^{(c)}\) is the set of labeled samples belonging to class \(c\), \(N_c = |\mathcal{D}_l^{(c)}|\) is the number of labeled samples in class \(c\). A pseudo-label \(\hat{y}\) for input \(x\) is accepted if both the model confidence and similarity satisfy thresholds:</p>
\[
p_T(\hat{y}\mid x) \ge \tau_{\mathrm{conf}}, \qquad 
s(x,\hat{y}) = \frac{\langle f_\theta(x), \mu_{\hat{y}} \rangle}{\|f_\theta(x)\|\|\mu_{\hat{y}}\|} \ge \tau_{\mathrm{sim}},
\]
<p>where \(p_T(\hat{y}\mid x)\) is the predicted probability of class \(\hat{y}\) from the teacher model \(T\), \(\mu_{\hat{y}} \in \mathbb{R}^d\) is the prototype (mean feature) for class \(\hat{y}\), \(\tau_{\mathrm{conf}}\) and \(\tau_{\mathrm{sim}}\) are empirically determined thresholds for confidence and similarity, respectively.</p>

<p>This induces two measurable statistics over \(\mathcal{D}_u\):</p>

<ul>
    <li><strong>Coverage</strong> \(f \in (0,1]\): fraction of pseudo-labels passing the filter,
    \[
    f = \frac{1}{|\mathcal{D}_u|}\sum_{x\in\mathcal{D}_u}\mathbb{I}\big[p_T(\hat{y}\mid x)\ge \tau_{\mathrm{conf}}, s(x,\hat{y})\ge\tau_{\mathrm{sim}}\big]
    \]
    </li>
    <li><strong>Precision</strong> \(\rho \in [0,1]\): conditional probability that an accepted pseudo-label is correct,
    \[
    \rho = \Pr[y=\hat{y}\mid \mathbb{I}=1]
    \]
    where \(y\) is the ground-truth label.
    </li>
</ul>

<p><em>Note:</em> Since the true labels \(y\) are not available for unlabeled data, \(\rho\) serves as a conceptual measure of the expected correctness of accepted pseudo-labels.</p>

<p>Accounting for filtering, the effective contribution of pseudo-labeled samples is:</p>
\[
\gamma_{\mathrm{eff}} = f \gamma,
\]
<p>where \(f\) is the fraction of pseudo-labels that pass the acceptance criteria.</p>

<h3>9.1 Pseudo-Label Error Dynamics under Prototype Refinement</h3>

<p>The student update, accounting for filtering with precision \(\rho\), can be expressed as:</p>
\[
\epsilon_s(t+1)
= (1-f\gamma)\epsilon_0 + f\gamma(1-\rho)\epsilon_t(t).
\]
<p>Here \((1-\rho)\) captures the proportion of incorrect pseudo-labels that survive prototype filtering. When \(\rho=1\), all pseudo-labels are correct and the student fully benefits from unlabeled supervision; when \(\rho=0\), the model ignores pseudo-labels, reducing to a purely supervised learner.</p>

<p>The teacher parameters are updated through an exponential moving average:</p>
\[
\epsilon_t(t+1)
= \alpha\epsilon_t(t) + (1-\alpha)\epsilon_s(t+1)
= \big[\alpha + (1-\alpha)f\gamma(1-\rho)\big]\epsilon_t(t)
  + (1-\alpha)(1-f\gamma)\epsilon_0,
\]
<p>where \(\alpha\) is the decay rate of the EMA. Defining the effective recurrence coefficient:</p>
\[
\lambda_{\mathrm{eff}} = \alpha + (1-\alpha)f\gamma(1-\rho),
\]

<p>For bounded error propagation (stability), \(\lambda_{\mathrm{eff}} < 1\), which yields:</p>
\[
f\gamma(1-\rho) < 1,
\]
\[
\Rightarrow \quad \rho > 1 - \frac{1}{f\gamma}.
\tag{13}
\]
<p>Equation (13) highlights that when pseudo-labels are highly reliable (high precision \(\rho\)), 
the student can safely use a larger fraction of pseudo-labeled data (\(f\gamma\)) without destabilizing training. 
Conversely, if pseudo-labels are less reliable (low \(\rho\)), 
only a smaller fraction of pseudo-labeled data should be used to prevent error amplification.</p>

<p>Provided that \(\lambda_{\mathrm{eff}} < 1\), Equation (12) shows that the teacher error asymptotically converges to:</p>
\[
\epsilon_\infty
= \frac{(1-\alpha)(1-f\gamma)\epsilon_0}{1-\lambda_{\mathrm{eff}}}
= \frac{(1-f\gamma)\epsilon_0}{1-f\gamma(1-\rho)}.
\tag{14}
\]
<p>Equation (14) quantifies how PLR influences long-term model performance.</p>

<div class="theorem">
    <div class="theorem-title">Theorem 2 (Prototype-Guided Pseudo-Label Refinement)</div>
    Let \(\epsilon_0>0\) denote the baseline teacher error on labeled data.  
    In a student-teacher semi-supervised framework with pseudo-label weight \(\gamma \in (0,1)\), EMA decay \(\alpha \in [0,1)\), and prototype-guided refinement with coverage \(f \in (0,1]\) and precision \(\rho \in [0,1]\), the asymptotic teacher error with PRL is
    \[
    \epsilon_\infty^{\mathrm{PRL}} = \frac{(1-f\gamma)\,\epsilon_0}{1 - f\gamma(1-\rho)}.
    \]
    Under the stability condition \(\lambda_{\mathrm{eff}} := \alpha + (1-\alpha) f \gamma (1-\rho) < 1\), the following hold:
    <ol>
        <li><strong>(Reduced asymptotic error)</strong> \(\epsilon_\infty^{\mathrm{PRL}} \le \epsilon_0\), with strict inequality if \(f\gamma>0\) and \(\rho>0\).</li>
        <li><strong>(Monotonicity in precision)</strong> \(\frac{\partial \epsilon_\infty^{\mathrm{PRL}}}{\partial \rho} < 0\), so higher precision strictly reduces asymptotic error.</li>
        <li><strong>(Safe pseudo-label budget)</strong> Stable error propagation is maintained for all \(f\gamma < \frac{1}{1-\rho}\), allowing larger pseudo-label usage at higher precision.</li>
    </ol>
</div>

<div class="proof">
    <div class="proof-title">Proof:</div>
    
    <p>From the analysis in Section 9.1, the teacher error evolves as a first-order linear recurrence:</p>
    \[
    \epsilon_t(t+1) = \lambda_{\mathrm{eff}} \epsilon_t(t) + (1-\alpha)(1-f\gamma)\epsilon_0,
    \]
    <p>where,</p>
    \[
    \lambda_{\mathrm{eff}} = \alpha + (1-\alpha) f \gamma (1-\rho).
    \]
    <p>For \(|\lambda_{\mathrm{eff}}|<1\), solving the recurrence yields the asymptotic error:</p>
    \[
    \epsilon_\infty^{\mathrm{PRL}} = \frac{(1-\alpha)(1-f\gamma)\epsilon_0}{1-\lambda_{\mathrm{eff}}}.
    \]
    <p>Substituting \(\lambda_{\mathrm{eff}}\) and simplifying the denominator:</p>
    \[
    1 - \lambda_{\mathrm{eff}} = 1 - \alpha - (1-\alpha)f\gamma(1-\rho)
    = (1-\alpha)[1 - f\gamma(1-\rho)],
    \]
    <p>we obtain:</p>
    \[
    \epsilon_\infty^{\mathrm{PRL}} = \frac{(1-\alpha)(1-f\gamma)\epsilon_0}{(1-\alpha)[1 - f\gamma(1-\rho)]} = \frac{(1-f\gamma)\epsilon_0}{1 - f\gamma(1-\rho)}.
    \]
    
    <h4>Part 1: Reduced Asymptotic Error</h4>
    <p>Define the error ratio:</p>
    \[
    R := \frac{\epsilon_\infty^{\mathrm{PRL}}}{\epsilon_0} = \frac{1-f\gamma}{1 - f\gamma(1-\rho)}.
    \]
    <p>Rewriting the denominator:</p>
    \[
    1 - f\gamma(1-\rho) = 1 - f\gamma + f\gamma\rho.
    \]
    
    <p><em>Case 1:</em> If \(f\gamma = 0\) (no pseudo-labels used) or \(\rho = 0\) (all accepted pseudo-labels incorrect):</p>
    \[
    1 - f\gamma(1-\rho) = 1 - f\gamma \implies R = 1 \implies \epsilon_\infty^{\mathrm{PRL}} = \epsilon_0.
    \]
    
    <p><em>Case 2:</em> If \(f\gamma > 0\) and \(\rho > 0\):</p>
    \[
    f\gamma\rho > 0 \implies 1 - f\gamma + f\gamma\rho > 1 - f\gamma.
    \]
    <p>Under the stability condition, both numerator and denominator are positive, so:</p>
    \[
    R = \frac{1-f\gamma}{1-f\gamma+f\gamma\rho} < 1 \implies \epsilon_\infty^{\mathrm{PRL}} < \epsilon_0 = \epsilon_\infty^{\mathrm{noPRL}}.
    \]
    <p>This establishes Part (1). \(\square\)</p>
    
    <h4>Part 2: Monotonicity in Precision</h4>
    <p>Taking the derivative of \(\epsilon_\infty^{\mathrm{PRL}}\) with respect to \(\rho\):</p>
    \[
    \frac{\partial \epsilon_\infty^{\mathrm{PRL}}}{\partial \rho} = \frac{\partial}{\partial \rho}\left[\frac{(1-f\gamma)\epsilon_0}{1-f\gamma(1-\rho)}\right].
    \]
    <p>Let \(u = 1 - f\gamma(1-\rho)\), so \(\frac{\partial u}{\partial \rho} = f\gamma\). Applying the chain rule:</p>
    \[
    \frac{\partial \epsilon_\infty^{\mathrm{PRL}}}{\partial \rho} = (1-f\gamma)\epsilon_0 \cdot \frac{\partial}{\partial \rho}\left[\frac{1}{u}\right]
    = (1-f\gamma)\epsilon_0 \cdot \left(-\frac{1}{u^2}\right) \cdot f\gamma
    = -\frac{(1-f\gamma)f\gamma\epsilon_0}{[1-f\gamma(1-\rho)]^2}.
    \]
    <p>Since all factors are positive under stability (\(f\gamma \in (0,1)\), \(\epsilon_0 > 0\), and \(1-f\gamma(1-\rho) > 0\) from \(\lambda_{\mathrm{eff}} < 1\)), we have:</p>
    \[
    \frac{\partial \epsilon_\infty^{\mathrm{PRL}}}{\partial \rho} < 0.
    \]
    <p>Higher precision strictly reduces asymptotic error, establishing Part (2). \(\square\)</p>
    
    <h4>Part 3: Safe Pseudo-Label Budget</h4>
    <p>The stability condition requires \(\lambda_{\mathrm{eff}} < 1\):</p>
    \[
    \alpha + (1-\alpha)f\gamma(1-\rho) < 1
    \]
    \[
    (1-\alpha)f\gamma(1-\rho) < 1 - \alpha
    \]
    \[
    f\gamma(1-\rho) < 1
    \]
    \[
    f\gamma < \frac{1}{1-\rho}.
    \]
    <p>This bound quantifies the maximum effective pseudo-label usage that maintains bounded error propagation. Higher precision \(\rho\) allows proportionally larger pseudo-label budgets \(f\gamma\) while maintaining identical stability guarantees. This establishes Part (3). \(\square\)</p>
    
    <p>Prototype-guided pseudo-label refinement guarantees that the asymptotic teacher error satisfies 
    \(\epsilon_\infty^{\mathrm{PRL}} \le \epsilon_0\), ensuring that filtered pseudo-labels do not degrade performance. 
    The asymptotic error decreases monotonically with pseudo-label precision, and the effective pseudo-label budget \(f\gamma\) 
    can be safely increased under the stability constraint:
    \[
    f\gamma < \frac{1}{1-\rho}.
    \] 
    This provides a quantitative criterion for safe pseudo-label utilization, showing that investing in pseudo-label quality via prototype-based filtering simultaneously reduces long-term error and enlarges the permissible pseudo-label budget, thereby expanding robust training regimes for semi-supervised learning.</p>
</div>

</body>
</html>
